{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5179,  0.3022,  0.8384],\n",
      "        [ 0.8703,  0.0929,  0.3813],\n",
      "        [ 0.0551,  0.1531,  0.8949],\n",
      "        [ 0.5342,  0.9241,  0.4972],\n",
      "        [ 0.2732,  0.8925,  0.6214]])\n"
     ]
    }
   ],
   "source": [
    "x =  torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(5,3, dtype=torch.long)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "tensor([[ 0.0811,  0.4588,  0.3900],\n",
      "        [ 0.6597,  0.7343,  0.9619],\n",
      "        [ 0.4103,  0.8274,  0.0575],\n",
      "        [ 0.9582,  0.9144,  0.6768],\n",
      "        [ 0.0172,  0.1047,  0.1419]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,3, dtype=torch.double)\n",
    "print(x)\n",
    "\n",
    "x1 = torch.rand_like(x, dtype=torch.float)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9519,  1.5379,  1.3630],\n",
      "        [ 1.1379,  1.2422,  1.8587],\n",
      "        [ 1.4083,  1.6140,  1.7061],\n",
      "        [ 1.6237,  1.7795,  1.6019],\n",
      "        [ 1.5455,  1.0876,  1.3717]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y  = torch.rand_like(x)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor torch.DoubleTensor\n",
      "tensor([[ 1.9519,  1.5379,  1.3630],\n",
      "        [ 1.1379,  1.2422,  1.8587],\n",
      "        [ 1.4083,  1.6140,  1.7061],\n",
      "        [ 1.6237,  1.7795,  1.6019],\n",
      "        [ 1.5455,  1.0876,  1.3717]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "resul = torch.empty(x.size(), dtype=torch.double)\n",
    "print(x.type(), y.type())\n",
    "torch.add(x, y, out=resul)\n",
    "print(resul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "tensor([[ 1.9519,  1.5379,  1.3630],\n",
      "        [ 1.1379,  1.2422,  1.8587],\n",
      "        [ 1.4083,  1.6140,  1.7061],\n",
      "        [ 1.6237,  1.7795,  1.6019],\n",
      "        [ 1.5455,  1.0876,  1.3717]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9519,  1.5379,  1.3630]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x[:1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 4)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "[[2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]]\n",
      "tensor([[ 2.,  2.],\n",
      "        [ 2.,  2.],\n",
      "        [ 2.,  2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((3,2))\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "b.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "y = x +2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f8990ad72b0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  27.],\n",
      "        [ 27.,  27.]]) tensor(27.)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f893d392240>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "tensor([[ 4.5000,  4.5000],\n",
      "        [ 4.5000,  4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "for param in params:\n",
    " print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1148, -0.0954,  0.0698, -0.0335, -0.1338,  0.1111,  0.0410,\n",
      "         -0.0037, -0.0322,  0.0175]])\n",
      "<AddmmBackward object at 0x7f893d3927f0>\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0289)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f8990b556d8>\n",
      "<AddmmBackward object at 0x7f8990ad7390>\n",
      "<ExpandBackward object at 0x7f8990b556d8>\n",
      "<AccumulateGrad object at 0x7f8990b55e80>\n"
     ]
    }
   ],
   "source": [
    "print (loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.conv1.bias.grad before\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]]])\n",
      "None\n",
      "net.conv1.bias.grad after\n",
      "tensor(1.00000e-02 *\n",
      "       [-1.3260, -0.0471,  1.2278, -0.1633, -1.0303,  0.3790])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[[ 0.2936, -0.0802, -0.4595,  0.7187,  0.3972],\n",
      "          [-0.4534, -2.3442,  2.9926, -0.0377,  1.0495],\n",
      "          [-1.0387, -0.6059, -1.2140,  2.1497,  0.7931],\n",
      "          [-0.5701, -0.3855, -0.5739,  1.9928, -0.8043],\n",
      "          [-0.4526, -0.3797,  0.5866,  2.3421, -1.9191]]],\n",
      "\n",
      "\n",
      "        [[[-1.1774, -1.3649, -0.7916,  0.4208,  0.1454],\n",
      "          [ 0.8492, -1.5162, -0.2896, -0.3020, -0.8924],\n",
      "          [-1.5676,  0.4441,  0.0351,  0.2126, -0.5379],\n",
      "          [-0.8231,  0.8129,  1.5350, -0.0449,  1.0229],\n",
      "          [-0.8329,  1.0610,  0.3915, -1.0797,  0.8646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0462,  1.1471,  1.2503,  0.5548, -1.1992],\n",
      "          [-1.6919,  1.7107, -1.1808, -0.8400,  0.0690],\n",
      "          [-0.6073,  0.1623, -0.9537,  1.0659,  0.8042],\n",
      "          [-0.1809,  0.9674,  0.6759,  0.5989, -0.0911],\n",
      "          [-1.3100,  0.5288, -2.2663, -0.5522, -2.1588]]],\n",
      "\n",
      "\n",
      "        [[[-0.1930, -2.1426, -0.4809, -0.2520, -0.5300],\n",
      "          [-2.1883,  0.0245, -2.0184, -2.0234, -0.2508],\n",
      "          [-0.8205,  1.5865, -0.3263, -0.4656,  1.8628],\n",
      "          [-1.8812, -1.5757, -0.5828, -0.6826,  1.7068],\n",
      "          [ 1.1555,  1.1615, -1.4406, -0.7055,  0.4188]]],\n",
      "\n",
      "\n",
      "        [[[-0.1738,  0.6702,  0.4392,  0.2840, -0.9127],\n",
      "          [ 0.5551, -1.0910, -1.1729, -0.3606, -0.7500],\n",
      "          [-0.2836, -0.4318,  0.1173, -0.0774, -0.7830],\n",
      "          [-0.3924,  0.3435,  0.3550, -0.1921, -0.9855],\n",
      "          [-0.8682,  1.8637,  1.7888,  0.8323,  0.2195]]],\n",
      "\n",
      "\n",
      "        [[[-2.4485,  0.0047,  1.3691, -1.1321, -1.6736],\n",
      "          [-0.6123, -0.2006,  1.8535, -0.3104,  0.4025],\n",
      "          [ 0.6110, -0.5649,  1.2308,  0.6978, -0.6494],\n",
      "          [ 0.6267, -0.2204,  0.9314, -1.1337, -0.7239],\n",
      "          [ 0.1996,  1.2113,  1.1845,  0.5475, -0.2807]]]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print('net.conv1.bias.grad before')\n",
    "print(net.conv1.bias.grad)\n",
    "print(net.conv1.weight.grad)\n",
    "print(net.conv1.weight.grad_fn)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('net.conv1.bias.grad after')\n",
    "print(net.conv1.bias.grad)\n",
    "print(net.conv1.weight.grad)\n",
    "print(net.conv1.weight.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
